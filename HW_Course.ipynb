{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93ed1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch import optim \n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN\n",
    "import mediapipe as mp\n",
    "import torchvision.transforms as tt\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89b25f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "          nn.Conv2d(1, 64, 3),\n",
    "          nn.LeakyReLU(),\n",
    "          nn.BatchNorm2d(64), \n",
    "          nn.Conv2d(64, 64, 3),\n",
    "          nn.LeakyReLU(),\n",
    "          nn.BatchNorm2d(64), \n",
    "          nn.MaxPool2d(2, 2), #16\n",
    "          nn.Conv2d(64, 128, 3),\n",
    "          nn.LeakyReLU(),          \n",
    "          nn.BatchNorm2d(128), \n",
    "          nn.Conv2d(128, 128, 3),\n",
    "          nn.LeakyReLU(),          \n",
    "          nn.BatchNorm2d(128),                     \n",
    "          nn.MaxPool2d(2, 2), #16\n",
    "          nn.Conv2d(128, 256, 3),\n",
    "          nn.LeakyReLU(),\n",
    "          nn.BatchNorm2d(256),           \n",
    "          nn.Conv2d(256, 512, 3),\n",
    "          nn.Flatten(),\n",
    "          nn.Linear(512, 1024),\n",
    "          nn.LeakyReLU(),    \n",
    "          nn.Dropout(0.2),\n",
    "          nn.BatchNorm1d(1024),                 \n",
    "          nn.Linear(1024, 1024),\n",
    "          nn.LeakyReLU(), \n",
    "          nn.Dropout(0.2),             \n",
    "          nn.BatchNorm1d(1024),                    \n",
    "          nn.Linear(1024, 100), \n",
    "          nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.mean_target_train = 0\n",
    "        self.mean_target_test = 0\n",
    "        self.history = None\n",
    "        self.device=device\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def fit(self, loader_train, loadre_test, epochs, loss, optimazer, lr, show_log=True):\n",
    "        self.train()\n",
    "        self.history = []\n",
    "        self.optimazer = optimazer(self.parameters(), lr)\n",
    "        self.loss = loss()\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            running_items = 0.0\n",
    "            predict_ture = 0.0            \n",
    "            for i, data in enumerate(loader_train):\n",
    "                X_train, y_train = data[0].to(self.device), data[1].to(self.device)\n",
    "                self.optimazer.zero_grad()\n",
    "                outputs = self(X_train)\n",
    "                loss_iter = self.loss(outputs, y_train)\n",
    "                loss_iter.backward()\n",
    "                self.optimazer.step()\n",
    "                if i%200 ==0:\n",
    "                    loss_test, acc_test = self.loss_fn(loader_test)\n",
    "                    self.history.append([epoch+1, i+1, acc_test])\n",
    "                    if show_log:\n",
    "                        print(f'Epoch [{epoch + 1:2}/{epochs}]. ' \\\n",
    "                              f'Step [{i + 1:3}/{len(loader_train)}]. ' \\\n",
    "                              f'Loss_test: {loss_test:.4f}  '\\\n",
    "                              f'Acc_test: {acc_test:.3f}'\n",
    "                              )\n",
    "                running_loss, running_items = 0.0, 0.0\n",
    "        print(f'Training is finished with optimazer: {optimazer}')\n",
    "        return self.history\n",
    "\n",
    "    \n",
    "    def loss_fn(self, loader):\n",
    "        self.eval()\n",
    "        running_loss = 0.0\n",
    "        running_items = 0.0\n",
    "        predict_ture = 0.0        \n",
    "        for i, data in enumerate(loader):\n",
    "            X_data, y_data = data[0].to(self.device), data[1].to(self.device)\n",
    "            outputs = self(X_data)\n",
    "            loss_iter = self.loss(outputs, y_data)\n",
    "            running_loss += loss_iter.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predict_ture += (y_data==predicted).sum().item()\n",
    "            running_items += len(y_data)\n",
    "        self.train()  \n",
    "        return running_loss / running_items, predict_ture/running_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5fa8252",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FaceDetector(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'        \n",
    "        # детектор лица\n",
    "        self.mtcnn = MTCNN() \n",
    "        # детектор руки\n",
    "        mpHands = mp.solutions.hands\n",
    "        self.hands = mpHands.Hands(False)\n",
    "        # загружаем модель\n",
    "        self.model = torch.load('G:\\\\Мой диск\\\\Colab Notebooks\\\\PyTorch\\\\lesson10\\\\model_1.pth', \n",
    "                                map_location=torch.device('cpu'))\n",
    "        self.model.eval()\n",
    "      \n",
    "        # Определяем трансформацию изображений с камеры\n",
    "        self.transform = tt.Compose([tt.Grayscale(num_output_channels=1),\n",
    "                         tt.ToTensor(),\n",
    "                         tt.Normalize(mean=[0.485],\n",
    "                                       std=[0.229])\n",
    "                       ])\n",
    "    \n",
    "        # Параметры вывода на экран результатов\n",
    "        self.font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        self.bottomLeftCornerOfText = (10,100)\n",
    "        self.fontScale              = 0.5\n",
    "        self.fontColor              = (255,255,255)\n",
    "        self.thickness              = 1\n",
    "        self.lineType               = 2\n",
    "    \n",
    "    \n",
    "    def face_detector(self, imgRGB):\n",
    "        '''Производит детекцию лица'''\n",
    "        flag = False\n",
    "        boxes, probs = self.mtcnn.detect(imgRGB, landmarks=False)\n",
    "        imgFace = imgRGB.copy()\n",
    "        \n",
    "        # если детекция успешна выдаёт положительный флаг и рисует баунтин бокс на изображении\n",
    "        if boxes is not None:  \n",
    "            flag = True\n",
    "            boxes = boxes.astype(int)\n",
    "            self._drawBoxes(imgFace, boxes, (255,0,0))\n",
    "        return imgFace, flag       \n",
    "\n",
    "\n",
    "    def hands_detector(self, imgRGB):\n",
    "        '''Производит детекцию руки'''        \n",
    "        results = self.hands.process(imgRGB)\n",
    "        imgHand = imgRGB.copy()\n",
    "        boxes = []    \n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            \n",
    "            # если детекция успешна то перебираем все полученные наборы      \n",
    "            for handLms in results.multi_hand_landmarks:\n",
    "                x_ = []\n",
    "                y_ = []\n",
    "                \n",
    "                # по точкам ищем границы руки, увеличиваем границы на величину padding, и \n",
    "                # получаем баунтинбокс для каждой руки\n",
    "                for id, lm in enumerate(handLms.landmark):\n",
    "                    x_.append(lm.x)\n",
    "                    y_.append(lm.y)\n",
    "                    h,w,c = imgRGB.shape\n",
    "                padding = 1.2\n",
    "                x_max = np.array(x_).max()*w\n",
    "                x_min = np.array(x_).min()*w\n",
    "                y_max = np.array(y_).max()*h\n",
    "                y_min = np.array(y_).min()*h\n",
    "                x_centr = (x_max+x_min)/2\n",
    "                y_centr = (y_max+y_min)/2\n",
    "                if x_max-x_min > y_max-y_min:\n",
    "                    delta = (x_centr - x_min)*padding\n",
    "                else:\n",
    "                    delta = (y_centr - y_min)*padding\n",
    "                    \n",
    "                X_min = x_centr-delta if x_centr-delta>=0 else 0\n",
    "                X_max = x_centr+delta if x_centr+delta<=w else w            \n",
    "                Y_min = y_centr-delta if y_centr-delta>=0 else 0\n",
    "                Y_max = y_centr+delta if y_centr+delta<=h else h \n",
    "                \n",
    "                boxes.append([int(X_min), int(Y_min), int(X_max), int(Y_max)])\n",
    "        \n",
    "        # рисуем баунтинбоксы на изображении        \n",
    "        self._drawBoxes(imgHand, boxes, (0,255,0))\n",
    "        return imgHand, boxes\n",
    "        \n",
    "        \n",
    "    def stackImages(self, scale,imgArray):\n",
    "        '''Метод стекирования всех изображений в одно в виде таблицы\n",
    "        scale - масштаб окна\n",
    "        imgArray - список изображений dim = 1 или 2\n",
    "        возвращает одно изображение в виде стека переданных ему изображений\n",
    "        '''\n",
    "        rows = len(imgArray)\n",
    "        cols = len(imgArray[0])\n",
    "        rowsAvailable = isinstance(imgArray[0], list)\n",
    "        width = imgArray[0][0].shape[1]\n",
    "        height = imgArray[0][0].shape[0]\n",
    "        if rowsAvailable:\n",
    "            for x in range ( 0, rows):\n",
    "                for y in range(0, cols):\n",
    "                    if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                        imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                    else:\n",
    "                        imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], \n",
    "                                                                     imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                    if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "            imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "            hor = [imageBlank]*rows\n",
    "            hor_con = [imageBlank]*rows\n",
    "            for x in range(0, rows):\n",
    "                hor[x] = np.hstack(imgArray[x])\n",
    "            ver = np.vstack(hor)\n",
    "        else:\n",
    "            for x in range(0, rows):\n",
    "                if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                    imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "                if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "            hor= np.hstack(imgArray)\n",
    "            ver = hor\n",
    "        return ver       \n",
    "        \n",
    "        \n",
    "    def _drawBoxes(self, frame, boxes, color):\n",
    "        \"\"\"\n",
    "        рисует баунтинбоксы на изображении\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for box in boxes:\n",
    "                cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), color, thickness=2)\n",
    "        except:\n",
    "            pass\n",
    "        return frame\n",
    "\n",
    " \n",
    "    def cropHand(self, imgRGB ,boxes):\n",
    "        '''Вырезает из изображения первый баунтинбокс и выдаёт GRAY изображение (32,32)'''\n",
    "        flag = False\n",
    "        if boxes != []:\n",
    "            flag = True\n",
    "            imgHand = imgRGB[boxes[0][1]:boxes[0][3], boxes[0][0]:boxes[0][2]].copy()\n",
    "        else:\n",
    "            imgHand = np.zeros_like(imgRGB) \n",
    "        resized_image = cv2.resize(imgHand, (32, 32))\n",
    "        resized_image = cv2.cvtColor(resized_image, cv2.COLOR_RGB2GRAY) \n",
    "        return resized_image, flag\n",
    "    \n",
    "\n",
    "    def run(self, cap): \n",
    "        '''Основной метод класса'''\n",
    "        if (cap.isOpened()== False): \n",
    "            print(\"Ошибка камеры\")\n",
    "        while(cap.isOpened()):\n",
    "            # Считываем кадр, и отображаем его по горизотали\n",
    "            ret, frame = cap.read()\n",
    "            frame = cv2.flip(frame,1)\n",
    "            flag_face = False \n",
    "            flag_hand = False    \n",
    "            \n",
    "            # если кадр считался удачно\n",
    "            if ret == True:\n",
    "                frame_RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  \n",
    "\n",
    "                # Производим детекцию лица и рисуем баунтинбокс\n",
    "                frame_RGB_face, flag_face = self.face_detector(frame_RGB)\n",
    "                \n",
    "                # Производим детекцию руки и рисуем баунтинбокс если нашли лицо\n",
    "                if flag_face:\n",
    "                    frame_RGB_hand, boxes = self.hands_detector(frame_RGB)\n",
    "                else:\n",
    "                    frame_RGB_hand = np.zeros_like(frame_RGB_face)\n",
    "                    boxes = []\n",
    "                \n",
    "                # Вырезаем из изображения руку\n",
    "                frame_crop_hand, flag_hand = self.cropHand(frame_RGB, boxes)\n",
    "                \n",
    "                # преобразуем руку в PIL формат производим трансформацию, такую же которую производили при обучении модели\n",
    "                # и возвращаем обратно в формат numpy\n",
    "                pil_image = Image.fromarray(frame_crop_hand)\n",
    "                self.transform(pil_image)\n",
    "                cv_image = np.array(pil_image)\n",
    "                \n",
    "                # подготавливаем и передаём изображение в модель\n",
    "                cv_image = cv_image[None, None, :,:]\n",
    "                class_ = np.argmax(self.model(torch.Tensor(cv_image)).detach().numpy())\n",
    "\n",
    "                # создаём картинку для отображения результатов\n",
    "                txt = ''                \n",
    "                if not flag_face:\n",
    "                    txt = f'No face detection'\n",
    "                if flag_face & (not flag_hand):\n",
    "                    txt = f'No hand detection'\n",
    "                if flag_face & flag_hand:\n",
    "                    txt = f'Class - {class_}'\n",
    "                \n",
    "                result = np.zeros((200,200,3), np.uint8)\n",
    "                cv2.putText(result,txt,\n",
    "                    self.bottomLeftCornerOfText,\n",
    "                    self.font,\n",
    "                    self.fontScale,\n",
    "                    self.fontColor,\n",
    "                    self.thickness,\n",
    "                    self.lineType)\n",
    "                # стекируем 4 изображения (изображение детектора лица, зображение детектора рук, \n",
    "                # изображение вырезанной руки, результат работы модели) \n",
    "                stak = self.stackImages(0.5, [[frame_RGB_face, frame_RGB_hand], [frame_crop_hand, result]])\n",
    "                cv2.imshow('Frame', stak)                \n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else: \n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "62cf6d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)  \n",
    "cap.set(3, 640) # Width\n",
    "cap.set(4, 480) # Lenght\n",
    "cap.set(10, 20) # Brightness\n",
    "\n",
    "fcd = FaceDetector()\n",
    "fcd.run(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f524ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
